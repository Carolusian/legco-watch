---
- name: Ensure Scrapy APT repo is present
  sudo: true
  apt_repository: >
    repo="deb http://archive.scrapy.org/ubuntu scrapy main"
    state=present

- name: ensure Scrapy APT repo key is present
  sudo: true
  apt_key: >
    keyserver=hkp://keyserver.ubuntu.com:80
    id=627220E7
    state=present

- name: Install Scrapyd
  sudo: true
  sudo_user: root
  apt: pkg=scrapyd state=installed update-cache=yes

- name: Copy over scrapyd upstart job
  sudo: true
  sudo_user: root
  template: >
    src=upstart-scrapyd.conf.j2
    dest=/etc/init/scrapyd.conf
    mode=0644
  notify:
    - Restart scrapyd

- name: Ensure scrapy daemon is in www-data group
  sudo: true
  user: >
    name=scrapy
    group={{project.group}}

- name: Ensure scrapy folder exists
  sudo: yes
  file: >
    path={{item}}
    owner=scrapy
    group={{project.group}}
    state=directory
    mode=0775
  with_items:
    - "{{scrapyd.dir}}"
  when: not is_vagrant

- name: Copy over scrapyd config
  sudo: true
  template: >
    src=scrapyd.conf.j2
    dest=/etc/scrapyd/conf.d/scrapyd.conf
    mode=0644
  notify:
    - Restart scrapyd

# This is the file that the FilesPipeline will try to write the downloads to
- name: Ensure files directory exists
  sudo: true
  file: >
    path={{scrapyd.files_dir}}/full
    owner={{project.user}}
    group={{project.group}}
    state=directory
    mode=775
